



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Leveraging BERT and a class-based TF-IDF to create easily interpretable topics.">
      
      
        <link rel="canonical" href="https://maartengr.github.io/bertopic/api/bertopic.html">
      
      
        <meta name="author" content="Maarten P. Grootendorst">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../icon.png">
      <meta name="generator" content="mkdocs-1.1, mkdocs-material-4.6.3">
    
    
      
        <title>BERTopic - BERTopic</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.adb8469c.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.86422ebf.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,400i,700%7CUbuntu+Mono&display=fallback">
        <style>body,input{font-family:"Ubuntu","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Ubuntu Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../style.css">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="blue">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#bertopic" tabindex="0" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://maartengr.github.io/bertopic/" title="BERTopic" aria-label="BERTopic" class="md-header-nav__button md-logo">
          
            <img alt="logo" src="../icon.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            BERTopic
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" aria-label="search" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/MaartenGr/BERTopic/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../index.html" class="md-tabs__link">
          Home
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../algorithm.html" class="md-tabs__link">
          BERTopic
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="bertopic.html" class="md-tabs__link md-tabs__link--active">
          API
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://maartengr.github.io/bertopic/" title="BERTopic" class="md-nav__button md-logo">
      
        <img alt="logo" src="../icon.png" width="48" height="48">
      
    </a>
    BERTopic
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/MaartenGr/BERTopic/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      Home
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        Home
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../index.html" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      BERTopic
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        BERTopic
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../algorithm.html" title="Algorithm" class="md-nav__link">
      Algorithm
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      API
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        API
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        BERTopic
      </label>
    
    <a href="bertopic.html" title="BERTopic" class="md-nav__link md-nav__link--active">
      BERTopic
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.fit" class="md-nav__link">
    fit()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.fit_transform" class="md-nav__link">
    fit_transform()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topic" class="md-nav__link">
    get_topic()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topic_freq" class="md-nav__link">
    get_topic_freq()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topics" class="md-nav__link">
    get_topics()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topics_freq" class="md-nav__link">
    get_topics_freq()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.load" class="md-nav__link">
    load()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.save" class="md-nav__link">
    save()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.transform" class="md-nav__link">
    transform()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.visualize_distribution" class="md-nav__link">
    visualize_distribution()
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="ctfidf.html" title="cTFIDF" class="md-nav__link">
      cTFIDF
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.fit" class="md-nav__link">
    fit()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.fit_transform" class="md-nav__link">
    fit_transform()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topic" class="md-nav__link">
    get_topic()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topic_freq" class="md-nav__link">
    get_topic_freq()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topics" class="md-nav__link">
    get_topics()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.get_topics_freq" class="md-nav__link">
    get_topics_freq()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.load" class="md-nav__link">
    load()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.save" class="md-nav__link">
    save()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.transform" class="md-nav__link">
    transform()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.model.BERTopic.visualize_distribution" class="md-nav__link">
    visualize_distribution()
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/MaartenGr/BERTopic/edit/master/docs/api/bertopic.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="bertopic"><code>BERTopic</code><a class="headerlink" href="#bertopic" title="Permanent link">&para;</a></h1>
<p>BERTopic is a topic modeling technique that leverages BERT embeddings and
c-TF-IDF to create dense clusters allowing for easily interpretable topics
whilst keeping important words in the topic descriptions.</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bert_model</code></td>
<td><code>str</code></td>
<td>Model to use. Overview of options can be found here https://www.sbert.net/docs/pretrained_models.html</td>
<td><code>'distilbert-base-nli-mean-tokens'</code></td>
</tr>
<tr>
<td><code>top_n_words</code></td>
<td><code>int</code></td>
<td>The number of words per topic to extract</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>nr_topics</code></td>
<td><code>int</code></td>
<td>Specifying the number of topics will reduce the initial number of topics to the value specified. This reduction can take a while as each reduction in topics (-1) activates a c-TF-IDF calculation. IF this is set to None, no reduction is applied.</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>n_gram_range</code></td>
<td><code>Tuple[int, int]</code></td>
<td>The n-gram range for the CountVectorizer. Advised to keep high values between 1 and 3. More would likely lead to memory issues.</td>
<td><code>(1, 1)</code></td>
</tr>
<tr>
<td><code>min_topic_size</code></td>
<td><code>int</code></td>
<td>The minimum size of the topic.</td>
<td><code>30</code></td>
</tr>
<tr>
<td><code>n_neighbors</code></td>
<td><code>int</code></td>
<td>The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation (UMAP).</td>
<td><code>15</code></td>
</tr>
<tr>
<td><code>n_components</code></td>
<td><code>int</code></td>
<td>The dimension of the space to embed into when reducing dimensionality with UMAP.</td>
<td><code>5</code></td>
</tr>
<tr>
<td><code>stop_words</code></td>
<td><code>Union[str, List[str]]</code></td>
<td>Stopwords that can be used as either a list of strings, or the name of the language as a string. For example: 'english' or ['the', 'and', 'I'].</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>verbose</code></td>
<td><code>bool</code></td>
<td>Changes the verbosity of the model, Set to True if you want to track the stages of the model.</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<p>If you want to use your own embeddings, use it as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Create embeddings</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create topic model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<p>Due to the stochastisch nature of UMAP, the results from BERTopic might differ
and the quality can degrade. Using your own embeddings allows you to
try out BERTopic several times until you find the topics that suit
you best.</p>
<h2 id="bertopic.model.BERTopic.fit"><code class="highlight"><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.fit" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
            <span class="n">embeddings</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fit the models (Bert, UMAP, and, HDBSCAN) on a collection of documents and generate topics</span>

<span class="sd">        Arguments:</span>
<span class="sd">            documents: A list of documents to fit on</span>
<span class="sd">            embeddings: Pre-trained document embeddings. These can be used</span>
<span class="sd">                        instead of the sentence-transformer model</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic import BERTopic</span>
<span class="sd">        from sklearn.datasets import fetch_20newsgroups</span>

<span class="sd">        docs = fetch_20newsgroups(subset=&#39;all&#39;)[&#39;data&#39;]</span>
<span class="sd">        model = BERTopic(&quot;distilbert-base-nli-mean-tokens&quot;, verbose=True).fit(docs)</span>
<span class="sd">        ```</span>

<span class="sd">        If you want to use your own embeddings, use it as follows:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic import BERTopic</span>
<span class="sd">        from sklearn.datasets import fetch_20newsgroups</span>
<span class="sd">        from sentence_transformers import SentenceTransformer</span>

<span class="sd">        # Create embeddings</span>
<span class="sd">        docs = fetch_20newsgroups(subset=&#39;all&#39;)[&#39;data&#39;]</span>
<span class="sd">        sentence_model = SentenceTransformer(&quot;distilbert-base-nli-mean-tokens&quot;)</span>
<span class="sd">        embeddings = sentence_model.encode(docs, show_progress_bar=True)</span>

<span class="sd">        # Create topic model</span>
<span class="sd">        model = BERTopic(None, verbose=True).fit(docs, embeddings)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_documents_type</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Fit the models (Bert, UMAP, and, HDBSCAN) on a collection of documents and generate topics</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>documents</code></td>
<td><code>List[str]</code></td>
<td>A list of documents to fit on</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embeddings</code></td>
<td><code>ndarray</code></td>
<td>Pre-trained document embeddings. These can be used instead of the sentence-transformer model</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<p>If you want to use your own embeddings, use it as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Create embeddings</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create topic model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.fit_transform"><code class="highlight"><span class="n">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.fit_transform" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                      <span class="n">documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
                      <span class="n">embeddings</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                                                              <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Fit the models on a collection of documents, generate topics, and return the docs with topics</span>

<span class="sd">        Arguments:</span>
<span class="sd">            documents: A list of documents to fit on</span>
<span class="sd">            embeddings: Pre-trained document embeddings. These can be used</span>
<span class="sd">                        instead of the sentence-transformer model</span>

<span class="sd">        Returns:</span>
<span class="sd">            predictions: Topic predictions for each documents</span>
<span class="sd">            probabilities: The topic probability distribution</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic import BERTopic</span>
<span class="sd">        from sklearn.datasets import fetch_20newsgroups</span>

<span class="sd">        docs = fetch_20newsgroups(subset=&#39;all&#39;)[&#39;data&#39;]</span>

<span class="sd">        model = BERTopic(&quot;distilbert-base-nli-mean-tokens&quot;, verbose=True)</span>
<span class="sd">        topics = model.fit_transform(docs)</span>
<span class="sd">        ```</span>

<span class="sd">        If you want to use your own embeddings, use it as follows:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic import BERTopic</span>
<span class="sd">        from sklearn.datasets import fetch_20newsgroups</span>
<span class="sd">        from sentence_transformers import SentenceTransformer</span>

<span class="sd">        # Create embeddings</span>
<span class="sd">        docs = fetch_20newsgroups(subset=&#39;all&#39;)[&#39;data&#39;]</span>
<span class="sd">        sentence_model = SentenceTransformer(&quot;distilbert-base-nli-mean-tokens&quot;)</span>
<span class="sd">        embeddings = sentence_model.encode(docs, show_progress_bar=True)</span>

<span class="sd">        # Create topic model</span>
<span class="sd">        model = BERTopic(None, verbose=True)</span>
<span class="sd">        topics = model.fit_transform(docs, embeddings)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_documents_type</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
        <span class="n">documents</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Document&quot;</span><span class="p">:</span> <span class="n">documents</span><span class="p">,</span>
                                  <span class="s2">&quot;ID&quot;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">)),</span>
                                  <span class="s2">&quot;Topic&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>

        <span class="c1"># Extract BERT sentence embeddings</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">check_embeddings_shape</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">documents</span><span class="p">)</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">documents</span><span class="o">.</span><span class="n">Document</span><span class="p">)</span>

        <span class="c1"># Reduce dimensionality with UMAP</span>
        <span class="n">umap_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce_dimensionality</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

        <span class="c1"># Cluster UMAP embeddings with HDBSCAN</span>
        <span class="n">documents</span><span class="p">,</span> <span class="n">probabilities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_embeddings</span><span class="p">(</span><span class="n">umap_embeddings</span><span class="p">,</span> <span class="n">documents</span><span class="p">)</span>

        <span class="c1"># Extract topics by calculating c-TF-IDF</span>
        <span class="n">c_tf_idf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_topics</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_topics</span><span class="p">:</span>
            <span class="n">documents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce_topics</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">)</span>
            <span class="n">probabilities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_probabilities</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">Topic</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">probabilities</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Fit the models on a collection of documents, generate topics, and return the docs with topics</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>documents</code></td>
<td><code>List[str]</code></td>
<td>A list of documents to fit on</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embeddings</code></td>
<td><code>ndarray</code></td>
<td>Pre-trained document embeddings. These can be used instead of the sentence-transformer model</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[List[int], numpy.ndarray]</code></td>
<td>predictions: Topic predictions for each documents     probabilities: The topic probability distribution</td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<p>If you want to use your own embeddings, use it as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Create embeddings</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create topic model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.get_topic"><code class="highlight"><span class="n">get_topic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topic</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.get_topic" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>430
431
432
433
434
435
436
437
438
439
440
441
442</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">get_topic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topic</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">bool</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Return top n words for a specific topic and their c-TF-IDF scores</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        topic = model.get_topic(12)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">topics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">topic</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Return top n words for a specific topic and their c-TF-IDF scores</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="n">topic</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.get_topic_freq"><code class="highlight"><span class="n">get_topic_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topic</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.get_topic_freq" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>455
456
457
458
459
460
461
462
463
464
465
466
467</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">get_topic_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">topic</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Return the the size of a topic</span>

<span class="sd">        Arguments:</span>
<span class="sd">             topic: the name of the topic as retrieved by get_topics</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        frequency = model.get_topic_freq(12)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">topic_sizes</span><span class="o">.</span><span class="n">items</span><span class="p">()[</span><span class="n">topic</span><span class="p">]</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Return the the size of a topic</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>topic</code></td>
<td><code>int</code></td>
<td>the name of the topic as retrieved by get_topics</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="n">frequency</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topic_freq</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.get_topics"><code class="highlight"><span class="n">get_topics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.get_topics" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>419
420
421
422
423
424
425
426
427
428</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">get_topics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot; Return topics with top n words and their c-TF-IDF score</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        all_topics = model.get_topics()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">topics</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Return topics with top n words and their c-TF-IDF score</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="n">all_topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topics</span><span class="p">()</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.get_topics_freq"><code class="highlight"><span class="n">get_topics_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.get_topics_freq" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>444
445
446
447
448
449
450
451
452
453</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">get_topics_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Return the the size of topics (descending order)</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        frequency = model.get_topics_freq()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_sizes</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Topic&#39;</span><span class="p">,</span> <span class="s1">&#39;Count&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;Count&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Return the the size of topics (descending order)</p>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="n">frequency</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topics_freq</span><span class="p">()</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.load"><code class="highlight"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code> <em>(classmethod)</em><a class="headerlink" href="#bertopic.model.BERTopic.load" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>614
615
616
617
618
619
620
621
622
623
624
625
626
627
628</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Loads the model from the specified path</span>

<span class="sd">        Arguments:</span>
<span class="sd">            path: the location and name of the BERTopic file you want to load</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        BERTopic.load(&quot;my_model&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Loads the model from the specified path</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>path</code></td>
<td><code>str</code></td>
<td>the location and name of the BERTopic file you want to load</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="n">BERTopic</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;my_model&quot;</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.save"><code class="highlight"><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.save" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>599
600
601
602
603
604
605
606
607
608
609
610
611
612</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Saves the model to the specified path</span>

<span class="sd">        Arguments:</span>
<span class="sd">            path: the location and name of the file you want to save</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        model.save(&quot;my_model&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Saves the model to the specified path</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>path</code></td>
<td><code>str</code></td>
<td>the location and name of the file you want to save</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;my_model&quot;</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.transform"><code class="highlight"><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.transform" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                  <span class="n">documents</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
                  <span class="n">embeddings</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; After having fit a model, use transform to predict new instances</span>

<span class="sd">        Arguments:</span>
<span class="sd">            documents: A single document or a list of documents to fit on</span>
<span class="sd">            embeddings: Pre-trained document embeddings. These can be used</span>
<span class="sd">                        instead of the sentence-transformer model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            predictions: Topic predictions for each documents</span>
<span class="sd">            probabilities: The topic probability distribution</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic import BERTopic</span>
<span class="sd">        from sklearn.datasets import fetch_20newsgroups</span>

<span class="sd">        docs = fetch_20newsgroups(subset=&#39;all&#39;)[&#39;data&#39;]</span>
<span class="sd">        model = BERTopic(&quot;distilbert-base-nli-mean-tokens&quot;, verbose=True).fit(docs)</span>
<span class="sd">        topics = model.transform(docs)</span>
<span class="sd">        ```</span>

<span class="sd">        If you want to use your own embeddings:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic import BERTopic</span>
<span class="sd">        from sklearn.datasets import fetch_20newsgroups</span>
<span class="sd">        from sentence_transformers import SentenceTransformer</span>

<span class="sd">        # Create embeddings</span>
<span class="sd">        docs = fetch_20newsgroups(subset=&#39;all&#39;)[&#39;data&#39;]</span>
<span class="sd">        sentence_model = SentenceTransformer(&quot;distilbert-base-nli-mean-tokens&quot;)</span>
<span class="sd">        embeddings = sentence_model.encode(docs, show_progress_bar=True)</span>

<span class="sd">        # Create topic model</span>
<span class="sd">        model = BERTopic(None, verbose=True).fit(docs, embeddings)</span>
<span class="sd">        topics = model.transform(docs, embeddings)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">documents</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">check_embeddings_shape</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">documents</span><span class="p">)</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

        <span class="n">umap_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">umap_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">membership_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_model</span><span class="p">,</span> <span class="n">umap_embeddings</span><span class="p">)</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">approximate_predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_model</span><span class="p">,</span> <span class="n">umap_embeddings</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapped_topics</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_predictions</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
            <span class="n">probabilities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_probabilities</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">probabilities</span> <span class="o">=</span> <span class="n">probabilities</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">probabilities</span>
</code></pre></div>
</td></tr></table>
</details>
<p>After having fit a model, use transform to predict new instances</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>documents</code></td>
<td><code>Union[str, List[str]]</code></td>
<td>A single document or a list of documents to fit on</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embeddings</code></td>
<td><code>ndarray</code></td>
<td>Pre-trained document embeddings. These can be used instead of the sentence-transformer model.</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Tuple[List[int], numpy.ndarray]</code></td>
<td>predictions: Topic predictions for each documents     probabilities: The topic probability distribution</td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<p>If you want to use your own embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Create embeddings</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;distilbert-base-nli-mean-tokens&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create topic model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="bertopic.model.BERTopic.visualize_distribution"><code class="highlight"><span class="n">visualize_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">,</span> <span class="n">min_probability</span><span class="o">=</span><span class="mf">0.015</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code><a class="headerlink" href="#bertopic.model.BERTopic.visualize_distribution" title="Permanent link">&para;</a></h2>
<details class="note"><summary>Show source code in <code>bertopic\model.py</code></summary><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">visualize_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                               <span class="n">probabilities</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                               <span class="n">min_probability</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.015</span><span class="p">,</span>
                               <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                               <span class="n">save</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Visualize the distribution of topic probabilities</span>

<span class="sd">        Arguments:</span>
<span class="sd">            probabilities: An array of probability scores</span>
<span class="sd">            min_probability: The minimum probability score to visualize.</span>
<span class="sd">                             All others are ignored.</span>
<span class="sd">            figsize: The size of the figure</span>
<span class="sd">            save: Whether to save the resulting graph to probility.png</span>

<span class="sd">        Usage:</span>

<span class="sd">        Make sure to fit the model before and only input the</span>
<span class="sd">        probabilities of a single document:</span>

<span class="sd">        ```python</span>
<span class="sd">        model.visualize_distribution(probabilities[0])</span>
<span class="sd">        ```</span>

<span class="sd">        ![](../img/probabilities.png)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Get values and indices equal or exceed the minimum probability</span>
        <span class="n">labels_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">probabilities</span> <span class="o">&gt;=</span> <span class="n">min_probability</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">labels_idx</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="c1"># Create labels</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">labels_idx</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">words</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
                    <span class="n">label</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">label</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\bf{Topic }$ &quot;</span> <span class="o">+</span>
                            <span class="sa">r</span><span class="s2">&quot;$\bf{&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:}$ &quot;</span> <span class="o">+</span>
                            <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
                <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">vals</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vals</span><span class="p">))</span>

        <span class="c1"># Create figure</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">pos</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="n">vals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#333F4B&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">vals</span><span class="p">),</span> <span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">vals</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#333F4B&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

        <span class="c1"># Set ticks and labels</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#333F4B&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Topic Probability Distribution&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#333F4B&#39;</span><span class="p">)</span>

        <span class="c1"># Update spine style</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_bounds</span><span class="p">(</span><span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_bounds</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">vals</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_position</span><span class="p">((</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_position</span><span class="p">((</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">))</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">save</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;probability.png&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
</details>
<p>Visualize the distribution of topic probabilities</p>
<p><strong>Parameters</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>probabilities</code></td>
<td><code>ndarray</code></td>
<td>An array of probability scores</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>min_probability</code></td>
<td><code>float</code></td>
<td>The minimum probability score to visualize. All others are ignored.</td>
<td><code>0.015</code></td>
</tr>
<tr>
<td><code>figsize</code></td>
<td><code>tuple</code></td>
<td>The size of the figure</td>
<td><code>(10, 5)</code></td>
</tr>
<tr>
<td><code>save</code></td>
<td><code>bool</code></td>
<td>Whether to save the resulting graph to probility.png</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<p>Make sure to fit the model before and only input the
probabilities of a single document:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">visualize_distribution</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
<p><img alt="" src="../img/probabilities.png" /></p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../algorithm.html" title="Algorithm" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Algorithm
              </span>
            </div>
          </a>
        
        
          <a href="ctfidf.html" title="cTFIDF" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                cTFIDF
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 Maintained by <a href="https://github.com/MaartenGr">Maarten</a>.
          </div>
        
        powered by
        <a href="https://www.mkdocs.org" target="_blank" rel="noopener">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.c33a9706.js"></script>
      
      <script>app.initialize({version:"1.1",url:{base:".."}})</script>
      
    
  </body>
</html>